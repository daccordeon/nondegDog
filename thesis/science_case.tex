\chapter{Nondegenerate internal squeezing for gravitational-wave detection}
\label{chp:science_case}

% be clear about the scope of this project, I am not wanting to recommend the design of the next detector to be built, this is exploratory work into a configuration that has never been modelled this thoroughly before -- more would need to be done (e.g. add in external squeezing and thermal noise etc.) to make a proper judgement which is not my aim.
% comparison to existing proposals
% conclusions from this chapter: nIS is feasible as an alternative to sWLC and to improve the sensitivity from 100-1000 Hz, but improving 1-4 kHz sensitivity appears less likely without changing the sloshing frequency and arm bandwidth

In this chapter, I consider using nondegenerate internal squeezing in a future gravitational-wave detector. This is exploratory work and I will not determine the optimal configuration for a future detector. Instead, I will focus on the general feasibility of nondegenerate internal squeezing. % and whether it warrants further investigation.
Firstly, I will examine the tolerance of nondegenerate internal squeezing to the realistic optical losses in a future detector like LIGO~Voyager as described in Chapter~\ref{chp:proposals} and compare it to the loss tolerance of degenerate internal squeezing. I will also discuss the optimal squeezing value for the sensitivity. Secondly, I will compare the realistic sensitivity of nondegenerate internal squeezing to stable optomechanical filtering and discuss whether nondegenerate internal squeezing is a viable, all-optical alternative. Finally, I will compare the sensitivity to a target for kilohertz gravitational-wave detection to determine if the kilohertz improvement is promising enough to warrant further investigation. Although this work was motivated by improving kilohertz sensitivity, I will also discuss whether the configuration is better suited to a broadband detector. %, which will be further explored in the next chapter.

\section{Tolerance to optical loss}
\label{sec:nIS_tolerance_to_losses}

% % table: parameter sets to compare
% \begin{table} %https://www.tablesgenerator.com/
% \centering
% \begin{tabular}{lllllll}
% parameter & Advanced LIGO & LIGO Voyager & NEMO & liBroadbandSensitivityImprovement2020 & Korobko2019 & miaoDesignGravitationalWaveDetectors2018 \\
% carrier wavelength &  &  &  &  &  &  \\
% arm cavity length &  &  &  &  &  &  \\
% signal-recycling cavity length &  &  &  &  &  &  \\
% circulating arm power &  &  &  &  &  &  \\
% input test mass transmissivity &  &  &  &  &  &  \\
% signal-recycling mirror transmissitivty &  &  &  &  &  &  \\
% test mass mass &  &  &  &  &  &  \\
% sloshing frequency &  &  &  &  &  &  \\
% signal readout rate &  &  &  &  &  &  \\
% optical losses &  &  &  &  &  & 
% \end{tabular}
%     \caption{\jam{(Fill in table, what detectors/parameters should be shown?)} Table of interferometer parameter sets, showing configuration and derived parameters. The parameter set from Ref.~\cite{} is based on LIGO~Voyager but directly sets the readout rate $\gamma_R$ and sloshing frequency $\omega_s$ and back-forms the corresponding physical lengths and reflectivities. \jam{(Freedoms in this process)}}
%     \label{tab:parameter_sets}
% \end{table}

% plot: tolerance to each of the four sources, matrix plot each against readout rate
% some way to mega matrix all of these, or just show sensitivity and not N and S separetely?
\begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{nIS_sigRO_tolerance_Rpd.pdf}
    \caption{\jam{(Why does squeezer-off RP worsen with readout rate?)} Nondegenerate internal squeezing tolerance to detection loss. The loss uniformly scales the signal to zero and the noise to the vacuum value. The system is more resilient around the anti-squeezed peak and where radiation-pressure noise dominates because the noise far from vacuum decreases approximately the same as the signal. This is an advantage over degenerate internal squeezing, see Section~\ref{sec:dIS_optical_loss}. The tolerance is independent of the signal readout rate. I use the parameter set in Tab.~\ref{tab:signal_RO_parameters}.}
    \label{fig:nIS_sigRO_tolerance_Rpd}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{nIS_sigRO_tolerance_Tlb.pdf}
    % Show effect of loss on squeezer-off system, likewise for following plots. --> too many curves
    \caption{\jam{(Check the effect of loss on the squeezer-off system, likewise for following plots, and mention it in the text. Check how changing the readout rate differently, i.e.\ Lsrc or Tsrm, affects the results, because only one affects the intra-cavity loss.)} Nondegenerate internal squeezing tolerance to signal mode intra-cavity loss.
    % The loss decreases the sensitivity around the signal peak and at higher frequencies depending on the readout rate, but not at low frequencies except with high readout rates, e.g.\ 50~kHz.
    The system appears highly resilient to realistic levels of this loss, e.g.\ even unrealistically high $10\%$ loss only causes a factor of two decrease in the peak sensitivity \jam{(check)}. At higher readout rates, e.g.\ 50~kHz, the tolerance worsens but remains high \jam{(quantify and explain this)}. I use the parameter set in Tab.~\ref{tab:signal_RO_parameters}.
    % The peak frequency of the signal and noise amplification changes because the loss changes the singularity threshold frequency \jam{(is there a physical reason?)}.
    }
    \label{fig:nIS_sigRO_tolerance_Tlb}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{nIS_sigRO_tolerance_Tlc.pdf}
    \caption{Nondegenerate internal squeezing tolerance to idler mode intra-cavity loss.
    % For readout rates around and below 5~kHz,
    The loss decreases the peak sensitivity and sensitivity from 100-1000~Hz but improves the radiation-pressure noise. The system is less tolerant to realistic levels of idler loss, e.g.\ 1000~ppm, than the other losses, even when the readout port is closed to the idler. At increased signal readout rate, this tolerance worsens until 50~kHz readout rate where the squeezer no longer improves the sensitivity \jam{(why?)}. The peak frequency changes because the threshold frequency changes. I use the parameter set in Tab.~\ref{tab:signal_RO_parameters}.}
    \label{fig:nIS_sigRO_tolerance_Tlc}
\end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{nIS_sigRO_tolerance_Tla.pdf}
%     \caption{\jam{(Purpose: show the different tolerance to different losses 4/4)} Nondegenerate internal squeezing tolerance to loss (4/4): arm intra-cavity loss. The realistic loss of 100~ppm has a negligible effect \jam{(quantify)} independently of readout rate. At large readout rates, e.g.\ above 5~kHz \jam{(check)}, the arm intra-cavity loss appears to have a negligible effect on the signal or noise even when far above the realistic level of 100~ppm \jam{(quantify this)}.}
%     \label{fig:nIS_sigRO_tolerance_Tla}
% \end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{nIS_sigRO_noise_budget.pdf}
%     \caption{\jam{(Purpose: show which noise dominates.)} Nondegenerate internal squeezing separate noise transfer functions for each loss port and the total noise response. The detection loss only affects the shot noise after the interferometer and therefore is flat. The other losses are all squeezed and affected by the radiation-pressure noise because they are coupled (in)directly to the signal-recycling and arm cavity modes. Below 100~Hz, the idler loss dominates the noise, and above 100~Hz the vacuum from the readout port dominates the noise. The other losses have minimal effect, e.g.\ they are 10~dB below the total noise. This is due to the relative size of the readout $T_\text{SRM}=0.046$ and realistic loss rates and the different tolerances to the different losses.}
%     \label{fig:nIS_sigRO_noise_budget}
% \end{figure}

% summarise the constraints from Chapter 3, give the table of parameters
I will compare how the sensitivity of nondegenerate internal squeezing degrades with each of the optical losses in the model. I will use the parameter set in Tab.~\ref{tab:signal_RO_parameters} which uses the realistic losses from Section~\ref{sec:dIS_optical_loss}~\footnote{Although this biases my analysis towards, e.g., low readout rate detectors, I mention the effect of changing the readout rate where relevant since it varies in the literature~\cite{}. \jam{(Is this a duplicate of another footnote?)}}.
% I will vary the signal readout rate of the detector by changing the length of the signal-recycling cavity \jam{(clarify that the signal-recycling mirror transmissivity could also be changed, and try this. Explain why the sensitivity does not improve at 50~kHz readout rate.)}~\footnote{Since I fix the sloshing frequency $\omega_s$ and change the signal readout rate $\gamma^b_\text{tot}$, if the signal-recycling cavity length changes then so must the input test mass transmissivity.}, as the range of future detectors considered in the literature can be partially characterised by different readout rates~\cite{}. E.g.\ the sloshing frequencies of Refs.~\cite{,,} lie within 2--6~kHz but their signal readout rates vary from 0.5--90~kHz. I compromise which parameters are fixed (e.g.\ circulating power, sloshing frequency) and which are varied (e.g.\ readout rate, losses, pump power) because I cannot examine the entire parameter space, which is why I do not claim that these parameters are optimal.
 % but at high readout rates, e.g. 50~kHz, the squeezer does not improve the sensitivity \jam{(explain why?)}
I consider the tolerance to detection, signal, idler, and arm losses in turn. I find the tolerance to a given loss by comparing the change in sensitivity if the loss is higher or lower than the realistic value, where no change indicates high tolerance. \jam{(criticise this method?)}

% resistant to detection losses, which is a big deal, although Caves's amplifier could alleviate this more generally
Firstly, as shown in Fig.~\ref{fig:nIS_sigRO_tolerance_Rpd}, realistic detection loss of $10\%$ has only a small effect on the sensitivity, at most a $10\%$ decrease, and the tolerance is better around the peak and below 100~Hz.
Detection loss uniformly scales down the signal response and pulls the noise response towards the vacuum value. At the peak and when radiation pressure noise dominates, the quantum noise is far enough above the vacuum level that the reduction in noise and signal are roughly the same and the sensitivity does not worsen. Away from the peak, the tolerance diminishes as the anti-squeezing decreases but the tolerance to detection loss is never worse than the base interferometer. This is unlike degenerate internal squeezing for the same losses in Section~\ref{sec:dIS_optical_loss} where the reliance on squeezing makes that system more vulnerable because the noise is below the vacuum value and therefore increases with losses. %However, both configurations can improve the detection loss by the inclusion of a Caves's amplifier from Section~\ref{sec:cavess_amp} which uses the same principle of anti-squeezing.

% resistant to signal loss, sensitive to arm loss, very sensitive to idler loss (SRM must be closed to idler through e.g. dichroic)
Secondly, as shown in Fig.~\ref{fig:nIS_sigRO_tolerance_Tlb}, signal mode intra-cavity loss at the realistic level has a negligible \jam{(quantify)} effect on nondegenerate internal squeezing. This is because the signal mode is dominated by loss through the readout port at $T_\text{SRM}=0.046=46000$~ppm compared to $T_{l,b}=1000~\text{ppm}$~\footnote{When I change the readout rate I fix the transmissivity of the signal-recycling mirror and change the cavity length \jam{(why don't I just change Tsrm? do this to compare.)}.}. % However, in the high signal loss limit, e.g.\ $T_{l,b}=0.1$, the loss dominates the readout rate, the peak frequency changes because the singularity threshold frequency is affected, and the tolerance worsens with the readout rate. \jam{(why?)} % because the bandwidth of the peak increases or the shorter cavity length at high readout rates also increases the intra-cavity loss rate?
% But this is not of concern to future detectors which are in the low signal loss regime.

% changing the readout rate changes the cavity length and therefore increases the idler loss
Thirdly, as shown in Fig.~\ref{fig:nIS_sigRO_tolerance_Tlc}, idler intra-cavity loss at the realistic level with zero idler readout rate already significantly degrades the sensitivity \jam{(quantify)}. Opening the idler readout port is equivalent to further increasing the idler loss for signal readout~\footnote{E.g.\ a readout port symmetric between signal and idler increases the idler loss to a transmissivity of $0.046$ in Fig.~\ref{fig:nIS_sigRO_tolerance_Tlc} \jam{(update this if Tsrm changes)}.}. Therefore, the idler readout port should be closed for signal readout. Increasing the idler loss also decreases the radiation-pressure noise \jam{(why?)}. With the idler readout port closed, the decrease in sensitivity from 100--1000~Hz by introducing 1000~ppm of realistic idler loss is comparable to introducing $50\%$ detection loss \jam{(looks worse than this? check this, does this idler loss dominate 0.1 detection loss?)}. The sensitivity is decreased more as the length of the cavity decreases, e.g.\ at higher readout rates, because all of the signal and idler loss rates increase. 
% idler loss modal equivalence to mechanical loss dominating sWLC?
% That idler loss is the dominant~\footnote{As measured in sensitivity change due to optical loss. The vacuum from the signal readout port is still the main vacuum source.} optical loss with these realistic losses \jam{(check this)} agrees with the optomechanical analogue being dominated by mechanical loss in the mechanical idler mode, see Section~\ref{sec:sWLC_loss}. %Unlike detection loss or the vacuum from the readout port, idler intra-cavity loss cannot be lowered by the use of external squeezers from Section~\ref{sec:external_squeezing}, making it a greater problem for using this configuration in future detectors.

Finally, realistic arm intra-cavity loss has a negligible effect on the sensitivity if the circulating power is fixed, which can be assumed~\cite{}. Even increasing the arm loss one hundred--fold only affects the sensitivity by less than \jam{... (quantify)}. Moreover, unlike the rest of the realistic future losses in Section~\ref{sec:dIS_optical_loss}, the arm loss is achievable today \jam{(check)} and therefore a high loss regime is irrelevant~\cite{}. % If the arm loss is made unrealistically high, then the effect on the sensitivity is similar to the idler mode loss except that it diminishes with increased idler readout rate \jam{(why?)}, but I do not consider this behaviour.
% Finally, as shown in Fig.~\ref{fig:nIS_sigRO_tolerance_Tla}, arm intra-cavity loss at the realistic level below 100~ppm has a negligible \jam{(quantify)} effect on the sensitivity. Although in the high arm loss limit in Section~\ref{sec:nOPO_reduction}, the noise response changes to become closer to a nondegenerate OPO than the lossless system, which explains the change in behaviour from 1000 to 10000~ppm \jam{(check gammas)} in Fig.~\ref{fig:nIS_sigRO_tolerance_Tla}, future detectors lie outside this regime. 
% Namely, future detectors lie in the regime explained in Section~\ref{sec:singularity_threshold} where the singularities have not merged, given by $$\gamma^c_\text{tot}\omega_s^2\geq\gamma_a\left(\omega_s^2+\gamma_a(\gamma^b_\mathrm{tot}+\gamma^c_\text{tot})\right).$$
% But this limit explains the change in behaviour for $T_{l,a}=0.01$ \jam{(why not when it's equal to idler loss?)} in Fig.~\ref{fig:nIS_sigRO_tolerance_Tla} when the signal readout rate is large \jam{(why?)}.

% summarise tolerances, noise budget in Fig.~\ref{fig:nIS_sigRO_noise_budget}
Therefore, the dominant realistic loss is idler loss even when the idler readout port is closed, the detection loss has a smaller effect \jam{(quantify)}, and the signal and arm intra-cavity losses have negligible effects \jam{(check)}. However, the dominant noise above 100~Hz is the shot noise from the readout port because of the relative sizes of the readout rate $T_\text{SRM}=46000~\text{ppm}$ compared to the realistic loss rates, e.g.\ 1000~ppm~\footnote{Here the detection loss $R_\text{PD}=0.1$ should instead be compared to $1-R_\text{PD}=0.9$ due to the vacuum reflected off the readout port also contributing.}. This agrees with the optomechanical analogue being limited by mechanical idler loss, see Section~\ref{sec:sWLC_loss}. 
\jam{(have I wrung all the information out of these plots?)}

\subsection{Comparison to degenerate internal squeezing}
% do I need to include this? it would be nice --> above comparison is the focus though,  keep this brief, might not be a subsection worth to say
% how to quantify difference in tolerance? is nIS more resistant than dIS?

As discussed in Section~\ref{sec:nIS_tolerance_to_losses}, the tolerance to optical loss is different between nondegenerate and degenerate internal squeezing. Comparing the two configurations for the same interferometer parameters and realistic losses shows that the nondegenerate case is more resilient to some losses, e.g.\ compare the effect of increasing the detection loss from $0.1$ to $0.5$ between Fig.~\ref{fig:dIS_loss_tolerance} and Fig.~\ref{fig:nIS_sigRO_tolerance_Rpd} and the effect of increasing the signal loss from 100~ppm to 1000~ppm between Fig.~\ref{fig:dIS_loss_tolerance} and Fig.~\ref{fig:nIS_sigRO_tolerance_Tlb} \jam{(quantify this, give total change in integrated sensitivity?)}. 
% \jam{(check that these figures compare, maybe use a different fig for nIS, and show lossless case in each)}
This is because of the general loss tolerance of squeezing versus anti-squeezing as discussed before. % as discussed in Section~\ref{sec:cavess_amp}. %, where loss always reduces the signal but can increase or decrease the noise depending on whether it is below or above the vacuum value, respectively.
However, both cases have similar tolerance to arm loss and the nondegenerate case has worse tolerance to idler loss than any of the degenerate case's tolerances, so the nondegenerate case is not universally more loss tolerant. \jam{(update conclusions/summaries accordingly)} \jam{(what can I say that is substantive?)}
% And since the nondegenerate case for realistic losses can be more sensitive, e.g.\ comparing the peak sensitivities of Figs.~\ref{fig:dIS_loss_tolerance}~\ref{fig:nIS_sigRO_tolerance_Tlc} \jam{(quantify peak sensitivity, check that readout rate the same)}, it is not clear which configuration is better overall -- which I will not determine. % -- which demonstrates the complications when comparing two configurations.
% And although degenerate internal squeezing can also perform internal anti-squeezing, it is only optimal to do so when the losses are high and beyond the regime of future detectors, as discussed in Section~\ref{sec:dIS_results}. 
% Therefore, as predicted in Section~\ref{sec:dIS_optical_loss}, nondegenerate internal squeezing is more resilient to optical loss than degenerate internal squeezing \jam{(can I claim this generally? what can I say that is substantive?)}.
Moreover, the sensitivity curves are not directly comparable and for different metrics the degenerate case might be more suitable, e.g.\ the nondegenerate case worsens the 10--50~Hz sensitivity which the degenerate case does not affect. %And Other considerations, such as the different tolerances to pump power, are necessary to decide between the two. 
Therefore, I conclude that the overall tolerance to losses of nondegenerate internal squeezing is at least comparable to degenerate internal squeezing and that can be an advantage to using the nondegenerate case, for example, in a high detection loss but low idler loss application \jam{(example?)}. \jam{(can I conclude something more concrete?)}


\subsection{Optimal squeezing}
\label{sec:nIS_optimal_squeezing}

% plot optimal squeezing curve (blue-green swoosh)
\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{nIS_optimum_squeezing.pdf}
	\caption{\jam{(Is this plot necessary?)} \jam{(Could cut the signal vs noise subplot. Check the red dot position by calculation.)} Nondegenerate internal squeezing's sensitivity versus noise (top panel) and signal versus noise (bottom panel) at a given frequency of $2.5$~kHz which is above the singularity threshold frequency \jam{(which is what value?)}, varying the squeezing parameter up to threshold. The sensitivity, noise, and signal are measured relative to their respective values at $2.5$~kHz without squeezing, e.g.\ the signal increase is $20\log_{10}(T_f/T_i)$ where $T_i$ is the signal response at $2.5$~kHz without squeezing and $T_f$ is with squeezing. Increasing the squeezing parameter increases the signal more than the noise up to a point, shown with a red dot, beyond which the signal decreases more than the noise as the peak frequency passes $2.5$~kHz. This shows that the optimal squeezer parameter \jam{(state the value here?)} for maximum sensitivity is below threshold. I use the parameter set in Tab.~\ref{tab:signal_RO_parameters}.
    % Although the optimal squeezer parameter also maximises the signal here, this is not necessarily always the case.
    %Compare to degenerate internal squeezing in Fig.~\ref{fig:dIS_optimal_squeezing}.
    }
	\label{fig:nIS_optimum_squeezing}
\end{figure}

\jam{(This section works without the figure. Is this subsection necessary? Could just move the explanation to singularity threshold section to explain that maximising sensitivity at a given frequency cannot find threshold.)}

% emphasise that threshold is not optimal squeezing for sensitivity
% Without detection loss, the optimal squeezing parameter for sensitivity is below threshold because the probe frequency is higher than the on-threshold peak frequency and with increased squeezer parameter the peak moves to lower frequencies. After the peak passes the probe frequency \jam{(show this?)} the signal and the noise start decreasing \jam{(check this)}. Increasing detection loss $R_\text{PD}$ decreases the signal $T$ as $\sqrt{1-R_\text{PD}}T$.
The optimal amount of squeezing for the maximum sensitivity is not necessarily on threshold. As shown in Fig.~\ref{fig:nIS_optimum_squeezing}, the sensitivity at a given, non-threshold frequency, here $2.5$~kHz which is above threshold \jam{(what is threshold)}, peaks at a point before threshold beyond which the amount that the signal is amplified more than the noise decreases.
This is because the peak frequency of the signal and noise changes with the squeezer parameter, and the optimal sensitivity is when it is aligned with the given frequency. This is unlike degenerate internal squeezing where the peak remains at the sloshing frequency for realistically low loss. %\jam{(The lossless case is not shown here because then the noise has no anti-squeezed peak. )}
% mention that this can be done for probe frequency, peak frequency, integral etc.
Conversely, this demonstrates that using the sensitivity at a particular frequency cannot reliably find threshold. %, which is also true for other metrics such as peak and integrated sensitivity \jam{(is it? check this using optimisation?)}. % and instead some other metric, e.g.\ the peak or integrated sensitivity, should be used.
% Choosing the metric to judge a configuration by is a difficult task because of the innate trade-off of peak sensitivity and bandwidth. I will return to this problem later when I compare the kilohertz and broadband performances of nondegenerate internal squeezing.


% \section{Comparison to existing proposals}
% The problem with making a judgement, emphasise that this result is not a clean decision, the best I can say is that they are comparable, nIS is feasible as an alternative to sWLC 

\section{Comparison to stable optomechanical filtering} % don't say versus
\label{sec:nIS_vs_sWLC}
% ultimately: is the all-optical approach a viable alternative? yes! but sWLC is not ruled out

% plot: with data from Fig. 5 in Li --> extract the plot and don't mess with the .nb further!
\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{nIS_vs_sWLC.pdf}
	\caption{Nondegenerate internal squeezing compared to stable optomechanical filtering where I use the data from Fig.~5 in Ref.~\cite{liBroadbandSensitivityImprovement2020} with permission from the authors~\cite{xiangLiPersonalCommunication}. The all-optical system's quantum noise--limited sensitivity with realistic optical loss is worse than the optomechanical system's quantum and thermal noise--limited sensitivity with low mechanical loss but is comparable to it if more ideal optical losses of 75~ppm in the arms and 100~ppm in the idler are used. I use the same $98.6\%$ ratio to threshold as the lossless case and Ref.~\cite{liBroadbandSensitivityImprovement2020}. I validate this comparison using the lossless models and the model for a single-cavity detector (with no signal-recycling cavity), which agree with Ref.~\cite{liBroadbandSensitivityImprovement2020}. I use the parameter set in Tab.~\ref{tab:signal_RO_parameters} which is the same as Ref.~\cite{liBroadbandSensitivityImprovement2020}.}
	\label{fig:nIS_vs_sWLC}
\end{figure}

I now consider whether nondegenerate internal squeezing is a viable, all-optical alternative to stable optomechanical filtering.
As discussed in Section~\ref{sec:modal_equivalence}, the only difference in the models of nondegenerate internal squeezing and stable optomechanical filtering is that the idler mode is optical and mechanical, respectively. This means that the idler loss has different values depending on whether it is optical or mechanical loss because of the different associated technologies.
% Therefore, to determine whether nondegenerate internal squeezing is a viable, all-optical alternative to the optomechanical analogue, I find the optical loss required to achieve the same sensitivity as the results in Ref.~\cite{liBroadbandSensitivityImprovement2020} that assume low mechanical loss and then determine whether the optical loss is as realistic as that low mechanical loss. 
% The key result is that I've found losses for nIS that replicate the results for sWLC: arm loss 75 ppm, idler loss 100 ppm. 
    %  Are these loss values more realistic than the thermal and mechanical constraints of sWLC? I think so, but I need back-up on this, forecasting future technological progress is hard to do rigourously or scientifically.
In Fig.~\ref{fig:nIS_vs_sWLC}, I find the optical loss required to achieve the same sensitivity as the results for the optomechanical analogue in Ref.~\cite{liBroadbandSensitivityImprovement2020} that assume low mechanical loss determined by $T_\text{env}=4$~K and $Q_m=8\times10^9$. %, where I compare the sensitivity to Fig.~5 of Ref.~\cite{liBroadbandSensitivityImprovement2020}.
To validate this comparison~\footnote{Although, I update $\chi$ to the lossy threshold $\chi_\text{thr}$ to maintain the same ratio as the lossless case, the authors in Ref.~\cite{liBroadbandSensitivityImprovement2020} do not update $\chi_m$ for the mechanical loss. By analogy to Fig.~\ref{fig:nIS_threshold_traj}, I suspect that their squeezing and therefore sensitivity is higher than it would be for a fixed ratio, but the effect is small, e.g.\ my lossy threshold values are $99\%$ and $99.9\%$ of the lossless threshold and the change in sensitivity is less than the difference between any of my curves in Fig.~\ref{fig:nIS_vs_sWLC}. Therefore, I ignore this effect and I leave a more accurate comparison to future work.}, I check that the lossless sensitivity and the sensitivity of a single-cavity detector agree with Ref.~\cite{liBroadbandSensitivityImprovement2020}. %I use the same $98.6\%$ ratio to threshold \jam{(check if $\chi_m$ changes)} and show that reducing it by $3\%$ decreases the peak but increases the bandwidth for the all-optical configuration and therefore I expect the same behaviour for the optomechanical analogue \jam{(check this?)}.
I show the sensitivity for the realistic losses from Section~\ref{sec:dIS_optical_loss} and for the lower, ``ideal'' losses of 75~ppm arm loss \jam{(why lower arm loss? try with 100~ppm since it is negligible.)} and 100~ppm idler loss with no idler readout rate. For these ideal optical losses, the peak sensitivity and bandwidth are better than the optomechanical analogue with low mechanical loss, but for the realistic losses the peak sensitivity is worse \jam{(check this)}. Although predicting future technological progress is not rigorous, losses somewhere between these realistic and ideal optical losses might be technologically possible~\cite{zhangBroadbandSignalRecycling2021,,} and the literature is similarly speculative \jam{(evidence?)} towards achieving the mechanical loss required for the optomechanical analogue~\cite{,}. Therefore, I find that the required optical loss is at least as realistic as the mechanical loss and conclude that nondegenerate internal squeezing is a viable, all-optical alternative to stable optomechanical filtering. \jam{(have I justified this conclusion? what are the limitations of this approach?)}
% Because of the equivalence in Section~\ref{sec:modal_equivalence}, I predict that the tolerance to other factors, e.g.\ pump power, is the same between the two configurations for equivalent losses.

% In summary, compared to the two configurations from Chapter~\ref{chp:proposals}, nondegenerate internal squeezing is neither definitively better nor worse, meaning that it warrants at least equal consideration as them \jam{(this evasive but what else can I say?)}, particularly for its greater tolerance to some of the losses. % particularly when the optical loss is high but the mechanical loss higher \jam{(I cannot directly compare these, what do I mean to say?)}.


\section{Feasibility for gravitational-wave detection}
\label{sec:nIS_sigRO_feasibility}

I now return to the motivating problem of improving kilohertz gravitational-wave sensitivity to detect new astrophysical sources. I will explore the feasibility of nondegenerate internal squeezing for both kilohertz (e.g. 1--4~kHz) and broadband (e.g. 100--4000~Hz) detection. I will reinforce that nondegenerate internal squeezing warrants further investigation by showing that its sensitivity is promising for detection even without external squeezing or increased circulating power. Again, I do not aim to find the best configuration for future detectors but instead will look at nondegenerate internal squeezing's performance for the LIGO~Voyager parameter set with varied readout rates which partially characterises the possible configurations.
% mention how optimisation could be done towards either goal against a variety of metrics, list some mutrics, but leave to future work
% Also, determining the best configuration would depend on the goal, e.g.\ kilohertz versus broadband sensitivity, and the metric used, e.g.\ sensitivity peak or integral against a kernel that biases certain frequencies~\cite{}, which I leave to future work with a more detailed model. 

% stress that the goal of this thesis is not to provide a recommendation to the designers of future gravitational wave detectors of what parameters to use, that task is much harder and would require the modelling of many other effects. This section (and thesis) is only exploratory in nature, and my conclusion is that nIS warrants more study because it appears to be able to get close enough to the targets (without increasing power) and is comparable to optomechanical alternative, and more resistant to detection losses than degenerate internal squeezing (operated in the squeezing not anti-squeezing pump phase).
% directly address the vagueness with ``is this configuration useful to GW detection'', talking about a particular parameter set or the best param set possible?

\subsection{Application to kilohertz detection}
\label{sec:nIS_kHz}

% plot: curve optimised for kilohertz
\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{nIS_ideal_losses.pdf}
    \caption{\jam{(Confirm that $\alpha$ GW-coupling is correct.)}  Nondegenerate internal squeezing's sensitivity compared to the astrophysical, kilohertz sensitivity target of $5\times10^{-25}\text{Hz}^{-1/2}$ from 1--4~kHz~\cite{miaoDesignGravitationalWaveDetectors2018}. Under ideal conditions, i.e.\ $95\%$ threshold, 75~ppm arm loss, 100~ppm idler loss, 500~Hz signal readout rate, and the idler readout port closed, the target can be achieved at the peak frequency. For more realistic losses (e.g.\ 1000~ppm idler loss), decreased squeezer parameter (e.g.\ $90\%$ threshold), and/or higher readout rate (not shown, e.g.\ 5~kHz) the target is not achieved \jam{(quantify how far off?)}. These results are without external squeezing. With 10~dB injected, frequency-dependent external squeezing~\cite{} as discussed in Section~\ref{sec:external_squeezing}, realistic losses and $95\%$ threshold can achieve the target at the peak frequency, where the realistic losses mean that the noise is only reduced by $7.2$~dB.
    % Among the losses, squeezer parameter, and readout rate, the changes in readout rate have the greatest effect \jam{(quantify change and effect, how to compare changes?)}. % and the squeezer parameter affects the low readout rate cases more \jam{(explain why)}.
    % Separate from the kilohertz target, the integrated sensitivity from 100--4000~kHz also improves \jam{(quantify)}.
    I use the parameter set in Tab.~\ref{tab:signal_RO_parameters} which has not been optimised for 1--4~kHz detection, and these results are without increased circulating power.}
    \label{fig:nIS_sens_target}
\end{figure}

\jam{(Check if Miao 2018 uses the same alpha value.)}
% achieving target across the band looks very unlikely, but target might be achievable at a particular kilohertz frequency
I consider using nondegenerate internal squeezing to detect kilohertz gravitational waves from Section~\ref{sec:kilohertz_GW}, which I represent with the case example of the binary neutron-star merger~\footnote{Other kilohertz astrophysical sources are predicted to require similar or greater sensitivity~\cite{}.}. The estimated sensitivity required to reliably detect a typical such ``post-merger'' signal~\footnote{Using current understanding which is conditioned on the very equations-of-state that are to be constrained by these measurements.} is $\sqrt{S_h}=5\times10^{-25} \mathrm{Hz}^{-1/2}$ from 1--4~kHz~\cite{miaoDesignGravitationalWaveDetectors2018}~\footnote{This target assumes the maximal detector response, i.e.\ from a gravitational wave with polarisation aligned to the arms~\cite{}.}.
In Fig.~\ref{fig:nIS_sens_target}, I compare this target to the sensitivity of nondegenerate internal squeezing with the realistic and ideal loss cases from Section~\ref{sec:nIS_vs_sWLC}. 
% From varying the readout rate, e.g.\ in Fig.~\ref{fig:nIS_sigRO_tolerance_Rpd}, I found that a low readout rate of $\sim 500$~Hz, such that the bandwidth of the peak is short compared to the arm cavity free-spectral range of $37.5$~kHz, achieves the best sensitivity from 1--4~kHz \jam{(why?)}.
For 500~Hz readout rate at $95\%$ threshold, the target is achieved at the peak frequency \jam{(give exact values)} with ideal losses but is not achieved for realistic losses \jam{(quantify how far off)} and/or decreased squeezing, e.g.\ at $90\%$ threshold \jam{(check this)}. I have experimented with what would be necessary to achieve the target across 1--4~kHz and I found that even at $99\%$ threshold with ideal losses, increased sloshing frequency \jam{(to what?)}, and readout rate to move the peak to the middle of the band \jam{(give value)}, the target could only be met from \jam{($\sim$~1--3~kHz, for the old value of alpha, check what is now possible)} where the arm cavity bandwidth limits further improvement \jam{(can I say this without proof?)}. 
% note the limitations with the target (conditions on a particular EoS of the neutron star etc.)
However, this target sensitivity and frequency range are not definitive as they depend on the equation-of-state of the neutron stars which is not well understood~\cite{}, indeed, understanding it better is one of the goals of kilohertz detection. And so, kilohertz improvement close to this target might be sufficient.
Although nondegenerate internal squeezing does not meet the target sensitivity from 1--4~kHz, it improves kilohertz sensitivity enough by itself that together with other improvements, such as external squeezing \jam{(quantify how much)}, it would be feasible with realistic losses, 90--95$\%$ squeezer parameter, and low readout rate \jam{(is there a problem with low readout rate?)} to achieve it for part of the band, as shown for 10~dB external squeezing \jam{(check the definition)} and realistic losses in Fig.~\ref{fig:nIS_sens_target}. This agrees with Ref.~\cite{miaoDesignGravitationalWaveDetectors2018} which achieved the target across 1--4~kHz using unstable optomechanical filtering~\footnote{There is not an exact correspondence between nondegenerate internal squeezing and the unstable case, but I reference it as a similar configuration that cannot achieve the target by itself but can with other improvements.} with 10~dB injected squeezing but with twice the circulating power. %, but I avoid increasing the circulating power as explained in Section~\ref{sec:circulating_power}.
Therefore, nondegenerate internal squeezing does not achieve the target across 1--4~kHz but its feasibility for kilohertz detection is still promising.
% The problem of improving kilohertz sensitivity is not resolved but this all-optical configuration shows some progress towards kilohertz detection.

    % Sensitivity target of 5e-25 from 1--4 kHz.
    %   With high squeezer ratio, i.e. 95\%, and ideal losses, then target can be hit for less than 1kHz of the band. With even higher squeezer ratio, i.e 99\%, and increased omegaS to move the peak into kHz (and corresponding increased gammaR), then the target can be hit for 1--3kHz.
    %       Bottom line: nIS can achieve the sensitivity target partially across the band, with more and more ideal conditions/optimisation of omegaS and gammaR necessary to widen the range that it achieves it at.
    %       Recommending a detector design isn't the goal of my project, but I do want to say something re: the sensitivity target. Right now, it sounds like nIS can achieve it at some peak frequency (under ideal conditions) but not from 1--4kHz for a Voyager-like detector.

\subsection{Application to broadband detection}
\label{sec:signalRO_broadband}

% plot: curve optimised for broadband --> not necessary? just point to Fig.~\ref{fig:nIS_sens_target} and mention optimisation as future work (and that preliminary results show ..., if that)
% \begin{figure}
%   \centering
%   % \includegraphics[width=\textwidth]{}
%   \caption{Nondegenerate internal squeezing sensitivity optimised for broadband detection (i.e.\ with integrated sensitivity from 0 to $\infty$ optimised).}
%   \label{fig:}
% \end{figure}

% kilohertz detection was the aim of the thesis but it looks like nIS might be more useful for a different purpose, set up idler readout chapter?
Although kilohertz detection motivated this work, the broadband improvement from 100--4000 Hz offered by nondegenerate internal squeezing, shown in Fig.~\ref{fig:nIS_sens_target}, could be used to detect more of the sources that detectors like Advanced~LIGO currently see~\cite{} but over a broader range of frequencies. For example, to observe a binary neutron-star merger from the inspiral to post-merger remnant~\cite{}, where only the late inspiral is currently seen~\cite{}. \jam{(are there other science applications of broadband detection?)} The next generation of detectors like LIGO~Voyager aim to improve the sensitivity beyond the current Advanced LIGO sensitivity of $\sqrt{S_h}=8\times10^{-24}\text{Hz}^{-1/2}$ around 100~Hz~\cite{PhysRevD.93.112004} \jam{(if I quote this sensitivity, then it should be shown in the plot)}, but Fig.~\ref{fig:nIS_sens_target} shows that nondegenerate internal squeezing further improves the sensitivity from 100--1000~Hz \jam{(quantify)}, along with the kilohertz improvement above, for realistic losses, $95\%$ threshold, and readout rates below 5 Hz. Here this broadband sensitivity improvement is less than the kilohertz improvement above \jam{(quantify)} because of the trade-off between peak sensitivity and bandwidth. This improvement is feasible and promising as long as the worsened radiation-pressure noise below 50~Hz is not an issue, e.g.\ it is not for binary neutron-star mergers~\cite{} \jam{(what is it an issue for? and give a 100-1000 Hz astrophysical target?)}. Therefore, nondegenerate internal squeezing should not just be considered for kilohertz sensitivity.


To improve both kilohertz and broadband detection, nondegenerate internal squeezing is a feasible configuration for future gravitational-wave detectors. To determine the optimal parameter set for a future detector, a more detailed model with effects such as pump depletion and higher-order modes \jam{(what would these effects change?)} could be optimised against some astrophysical metric~\cite{}. For example, for a broadband detector, the sensitivity integrated against a kernel that biases achieving a target sensitivity at each frequency but not going beyond it might be the appropriate metric. \jam{(should I give an equation? I want to show that I have considered this, but how much detail is sufficient?)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Chapter summary}

In this chapter, I have applied my model of nondegenerate internal squeezing to gravitational-wave detection and found that it warrants consideration for future detectors.
Firstly, I calculated the tolerance to the realistic optical loss expected in future detectors and found that the signal readout is limited by idler loss, affected by detection loss, and that signal and arm losses are negligible. In particular, signal readout requires the idler readout port to be closed to reduce the idler loss. This low tolerance to the idler loss means that the nondegenerate case is not universally more loss tolerant than degenerate internal squeezing but it is more tolerant to detection loss for example. I concluded that the comparable loss tolerance but different sensitivity curves of the two configurations make them likely suited to different purposes. 
% I also demonstrated that the optimal squeezer parameter for the sensitivity can be below threshold \jam{(is this worth mentioning again?)}.
Secondly, I showed that the optical loss required to match the performance of stable optomechanical filtering would require a comparable amount of technological progress to achieve as the low mechanical loss required for the optomechanical analogue \jam{(is this clear? is ``realistic'' a poor choice of word?)}. Therefore, I concluded that nondegenerate internal squeezing is a viable, all-optical alternative to that configuration.
% I also showed that nondegenerate internal squeezing is more resilient to optical loss than the degenerate case but that their sensitivity curves are not directly comparable which makes the cases useful for different purposes, e.g.\ the nondegenerate case affects the radiation-pressure noise \jam{(have I explained why?)} but the degenerate case does not.
Finally, I considered the motivating problem of improving kilohertz sensitivity and showed that, while nondegenerate internal squeezing does not achieve the particular astrophysical target for the entire 1--4~kHz band, it improves the sensitivity enough that it feasibly would enable and increase the detections of kilohertz gravitational waves. I also considered whether it is suited to broadband detection from 100--4000~kHz and found that it would improve the sensitivity in that band at the cost of radiation-pressure noise, making it a possible consideration for broadband detectors as well.

\jam{(Have I justified my conclusions and shown deep interpretation of the results to find the physics? I do not know what to add.)}


